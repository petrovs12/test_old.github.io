---
id: ba7ib85s4pc0ml8hf6u9l5w
title: email completion
desc: ''
updated: 1734699221249
created: 1734643700844
---


For the email completion system design task, we are going to go through the steps as follows. First, exploration of the problem space and requirement gathering. Second, framing the problem as an ML task. Exploring certain options and what broad model we might want to use based on the requirements. Three, what data we use. Do we clean it? Do we process it? How do we do the whole thing? Four, the specific model we want to use. How do we train it? Are there different stages of the training? Also, what would be the objective function to train with? Four, offline evaluation metrics and online evaluation metrics. Five, overall system design, how the system should work and what other components would be required for it. And six, maybe other considerations. For the first part, requirement gathering. What is the scope of the system? Do we have something basic? Do we need to use English or some other languages that we want to support? Second, what are the specifics of what we want to do? For example, maybe we want relatively simple completions. We want them short, we want them to the point. Latency is important. What do we want to do? How quickly do we want to respond? Probably we want a model that responds quite quickly to stuff. And it shows some kind of loading icon. Why is it lagging? And yeah, roughly that's basically the way we can go about it. Regarding the framing this problem as an ML task, I think what we want to do is consider... This seems like a sequence generation problem. Or perhaps a sequence... It looks like a generation problem from prompt. Or it could also be considered a completion problem. In general, we want to guess the next token. Yeah, we want to guess the next token. So most likely we're going to... Most likely we're going to want to sort of build a... Like okay, two options for transformers. And maybe LSTM or GRU or some other sequential model. In general, if we use a transformer, which is extremely popular lately, we want to use a decoder type of transformer. Where essentially we feed some tokens and we want to get the next tokens. Transformers have an advantage of being relatively... So I don't know actually what would be fast. They give generally quite good results. LSTM or like a sequence model could also be fine. In principle, because we want just a short sequence. But yeah, let's settle on transformers and then check later what's going on there. So roughly, the way that would work is that... We have the basic transformer kind of NLP transformer infrastructure setup. Where basically we have tokenization. So tokenization would get some text. And would return a matrix of size roughly equal to the number of words in the text. So this process is known as tokenization. What tokenization does is it maps certain text to a sequence of tokens. Which are chunking the text into parts. If you concatenate the tokens, you get the text back. There is also lemmization and stuff like normalization of the words. But basically then after we have the tokens. Each token is then mapped to a vector. And the vectors are high dimensional. And they describe each word or each token basically. Regarding the choice of tokenization procedure. What we want to have is... So we have something like we can chunk into letters. That gives very small embedding space. Because we have just 26 letters for English. You could have up to 60 letters, maybe 70 letters. And symbols counting all the capitals and punctuation. Maybe 75 or so. But the problem there is that this does not give us in any way some rich structure. It basically throws away a lot of information that is in the language. In terms of how letters are put together to create semantics. So that doesn't sound ideal. On the other hand if each word is embedded and used as a possible dimension. In a vector. Then this can be extremely highly dimensional as well. It can be like 500,000 words. That's also not great. And we could have some intermediate variants. Like splitting into syllables type thing. Or byte level encoding or something like that. Which is also used quite often



So, yeah, it's okay, then after we have figured out the tokenization... Oh, yeah, okay. So regarding the tokenization, I guess that's about that. So then, essentially, each token in the context is translated into a vector based on the embedding. And then, yeah, we predict from there. So there is some, there should be some diagram and some kind of, some kind of thing to, like there's some difference with offset of one that I need to figure out how exactly it works. So the next, the next topic would be then, okay, we have lemmatization, we have this, we have that.




Now let's talk about the data. So normally, the point with LLMs is that they have many, many, many, many, many parameters, and they're trying to optimize a certain objective function across many, many, many, many data points. And what ends up happening is that the landscape of this function is extremely bumpy and has extremely many local minima, local maxima, saddle points, and so on. And so we land up in some area of the... and also we have tons of symmetries. I guess we have like two to... yeah, like something... how many symmetries do you have? Every permutation of every layer... so okay, like if we have a fully connected neural net, at least every permutation of every layer induces a new symmetry. So you have at least like, you know, average number of nodes in the layer to the power of average of depth, something like this. At least this many symmetries, probably more than I can think of. But okay, so basically all around you have a bunch of similar points, but maybe those points are kind of better at performing a specific task. And so then what's often being done is we start with some pre-trained foundational model, and then we fine-tune it, meaning like continue training only certain parts of the data set. And generally, yeah, the gradients induced by a subset of the points would be different than the gradients induced by the whole data set, which would make it so that like task adaptation via gradient methods again is reasonable.


So in particular let's think about why would an LSTM be much worse than a transformer. I think actually the performance is quite similar. It could be the case that an LSTM and a transformer are comparable in this case, although I'm not really certain how the LSTM would perform given certain contexts. We would need a pre-trained LSTM which we then fine-tune the LSTM. Okay, so maybe this disqualifies it, but in general this is okay. So let's go with the transformer and then check the LSTM question. Also fine-tuning is fine-tuning. We basically just do the same as before but on the reduced dataset. It might work because we are already like a very capable in quotations place in the landscape and that's great. And yeah, that's what we want to do. And then when we fine-tune we actually have some other stuff going on. Sorry, we can specialize for a particular task and then this can work out very well.

another thing- [[science.math.Optimization.Optimal Control.Reinforcement Learning.RLHF]] 


So OK, we covered the optimization OK, let's cover a little bit of the data like yeah what what data we want to have. So roughly speaking and what they we want to fine tune with. So OK, let's say we have the pre train model and then we have like about a billion of email messages we can work with. We are probably going to strip out especially the useless part of the metadata. Namely, you know, some some stuff about the message being sent and tokens and yeah, whatever. I'm still not sure how to handle dates and timing in messages because they could be useful. Like in certain responses, especially when doing scheduling and referring to relative times and such. So probably. Yeah, like probably leave this in. So we will talk a nice kind of the maybe the email addresses. Together with the name of the person. We're going to maybe do it in a familiar format from certain question answering data sets to kind of combine combine features of question answering data sets and emails. Which, yeah, they should be kind of semantically similar. So we would also get rid of non english emails. That we will have some kind of content filtering with maybe with keywords or with some other model. That filters like no not safe for work or I mean whatever the the safety settings of our. Final intended use case are. And then we'll get a bunch of emails in the format. Like receiver. Like sender um. So like yeah, sender, receiver. Date, timestamp, subject line. And then the text content. Regarding attachments, I don't know, maybe we can also tokenize them. But probably this is out of scope of this exercise. Yeah, parsing and tokenizing. Arbitrary files is a difficult problem. So then what do we do then? We do like fine tuning or reinforcement learning. Could human feedback regarding the fine tuning task like self supervised learning could be a good approach with? Masking things. So basically we do masking of certain tokens and try to predict them. We are going. Probably want to add some inductive biases as well. So email responses would tend to be short. Yeah, that's, that's what I can think of in terms of the data. Yeah. And then finally we'll have some type of, you know, depth, some type of. OK, OK. So we need to think a little bit, uh, separately about uh, the objective function we want to optimize, and so how costly are false positives and false negatives? That is to say, I think if we have low confidence. Suggestions. We want to not suggest them. And so if the probability of a token being the next thing to complete is less than, I don't know certain threshold, which we can fine tune from intuition, maybe about 1520%. Like, we just don't show it. OK. Yeah, I think that's about. That about roughly covers. The system design so. In terms of, let's talk a little bit about offline and online evolution metrics. So in terms of offline evaluation metrics, I don't know if those are fully differentiable, but. There are some tech similarity scores such as Blue Rush, Meteor, Concordance and so on and so forth which might be useful gabriels to to shake and drag during training. I am not certain if any of them are differentiable, so if people training them, but I guess this is easy enough to check. So OK. What else in terms of online evaluations and AB testing and so on? Yeah, so. I guess what we want to optimize ultimately is. Improve task completion speed. For the customer, so maybe we want to track. Average times emails take. Average also may be average length of the correspondence because if like the child bolt is degrading the quality of. Responses and degrading the quality of the conversation. Then people would reach resolution slower or require more messages to do so. We want to, of course, more immediately track. Acceptance rate. Acceptance rate. X out rate maybe? If someone like, if someone rejects the suggestion several times in a row, we want to pop out the message and tell them that. And ask if they want to. Disable the feature altogether. Yeah, I think that's, that's what I can think about that and so. Regarding the overall system design, yeah, we we kind of covered them. And yeah. 


