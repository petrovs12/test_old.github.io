---
id: gagi2kq9z96aorpd54qns7q
title: Multi Modality
desc: ""
updated: 1733588461745
created: 1733588082816
---


# examples


2.1.1. Pre-trained Text Encoder
	•	CLIP Text Encoder:  uses a pre-trained text encoder from the Contrastive Language–Image Pre-training (CLIP) model developed by OpenAI.
	•	Function: The text encoder converts the input prompt into a continuous embedding vector that captures the semantic meaning of the text.

[[science.stats.Deep Neural Networks.Stable Diffusion]]
[[science.engineering.technologies.Data Visualization And Dashboards]]
