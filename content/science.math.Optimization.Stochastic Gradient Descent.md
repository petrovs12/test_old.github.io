---
id: xaya0m7gfq60u35wj1nyzuk
title: Stochastic Gradient Descent
desc: ""
updated: 2024-12-15T22:35
created: 1641834964579
---



[This article claims SGD considers only 1 example at a time.](https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a)


[This corraborates](https://optimization.cbe.cornell.edu/index.php?title=Stochastic_gradient_descent).

So SGD takes only 1 example, batch takes all, minibatch takes a subset of $n$ examples.
#minibatch #batch